# Palindrome Partitioning 🪞🔪


## Problem Statement 📝

Given a string `s`, return all possible partitions of `s` such that every substring in the partition is a palindrome.

Formally: find all sequences of indices `0 = i0 < i1 < i2 < ... < ik = n` such that every `s[ij: i(j+1)-1]` is a palindrome. Return the list of partitions where each partition is a vector of palindrome substrings.

**Example**

```
Input:  s = "aab"
Output: [["a","a","b"], ["aa","b"]]
```



### Intuition ✨

* We must choose cut positions between characters. For each starting index `ind`, we can try every end index `i ≥ ind`. If `s[ind..i]` is a palindrome, we can include that substring and then recursively solve for `i+1`.
* This is classic **backtracking**: build a current list `ds` of chosen palindrome substrings; when we reach the end of the string, record `ds` as one solution.
* The heavy part is repeated palindrome checks. Naively checking palindrome for each candidate substring costs `O(n)` and can blow up the runtime due to repeated work. Precomputing a boolean table `isPal[l][r]` using dynamic programming reduces each substring check to `O(1)` at the cost of `O(n^2)` preprocessing.

---

### Brute-force (naïve) 🐢

* Recursively try all `2^(n-1)` ways to cut the string, and for each candidate substring do an `O(n)` palindrome check → worst-case `O(n * 2^n)` time (very expensive).
* Works only for very small `n`.


### Optimal approach (backtracking + palindrome DP) ✅

1. Precompute a 2D boolean array `isPal[i][j]` telling whether `s[i..j]` is palindrome. This can be done in `O(n^2)` time and `O(n^2)` space.

   * Common DP: iterate `len` from `1` to `n`, and set `isPal[i][j] = (s[i]==s[j]) && (j-i<2 || isPal[i+1][j-1])`.
2. Backtrack from `ind = 0`:

   * For each `end` from `ind` to `n-1`, if `isPal[ind][end]` is `true`:

     * push `s.substr(ind, end-ind+1)` into `ds`
     * recurse from `end+1`
     * pop back
3. When `ind == n`, add a copy of `ds` to results.

This approach removes repeated palindrome recomputation, making the main cost the number of partitions generated and substrings copied.


### Annotated C++ code

Improvements vs the original snippet:

* Pass `s` by `const string&` to avoid copies.
* Precompute `isPal` table to make palindrome checks O(1).
* Reserve containers when helpful.
* Clean, commented, and production-ready.

```cpp
#include <bits/stdc++.h>
using namespace std;

class Solution {
public:
    vector<vector<string>> partition(const string &s) {
        int n = s.size();
        vector<vector<string>> res;
        vector<string> ds;
        if (n == 0) return res;

        // Precompute palindrome table: isPal[i][j] == true iff s[i..j] is a palindrome.
        vector<vector<bool>> isPal(n, vector<bool>(n, false));
        for (int len = 1; len <= n; ++len) {
            for (int i = 0; i + len - 1 < n; ++i) {
                int j = i + len - 1;
                if (s[i] == s[j]) {
                    if (len <= 2) isPal[i][j] = true;
                    else isPal[i][j] = isPal[i + 1][j - 1];
                } else {
                    isPal[i][j] = false;
                }
            }
        }

        ds.reserve(n); // optional micro-optimization
        backtrack(0, s, isPal, ds, res);
        return res;
    }

private:
    void backtrack(int ind, const string &s, const vector<vector<bool>> &isPal,
                   vector<string> &ds, vector<vector<string>> &res) {
        int n = s.size();
        if (ind == n) {
            res.push_back(ds);
            return;
        }
        for (int end = ind; end < n; ++end) {
            if (!isPal[ind][end]) continue;
            // s[ind..end] is a palindrome
            ds.push_back(s.substr(ind, end - ind + 1));
            backtrack(end + 1, s, isPal, ds, res);
            ds.pop_back();
        }
    }
};
```


### Complexity analysis 📊

Let `n = |s|`, and let `R` be the number of valid palindrome partitions produced (output size).

* **Backtracking:** every valid solution requires copying `O(n)` characters across its substrings, and the number of solutions `R` is problem-dependent (exponential in worst-case). Backtracking traversal combined with substring-copying leads to **time roughly** `O(n^2 + R * n)` in practice.

  * If we ignore output cost, the traversal explores partitions and each substring check becomes O(1) thanks to DP.
* **Space:** `O(n^2)` for the `isPal` table + `O(n)` recursion stack + `O(R * n)` for result storage.

**Bottom line:** Precomputation makes the algorithm feasible for typical constraints (e.g., `n ≤ 16–20` on contest platforms). Generating all partitions is inherently exponential if `s` allows many palindromic splits.

---

### Examples & test cases 🧪

1. **Example 1**

   ```
   s = "aab"
   Output: [["a","a","b"], ["aa","b"]]
   ```

2. **Single char**

   ```
   s = "a"
   Output: [["a"]]
   ```

3. **All same chars**

   ```
   s = "aaa"
   Output: [
     ["a","a","a"],
     ["a","aa"],
     ["aa","a"],
     ["aaa"]
   ]
   ```

4. **No multi-char palindromes**

   ```
   s = "abc"
   Output: [["a","b","c"]]
   ```

5. **Longer mixed**

   ```
   s = "aabbaa"
   Many partitions: ["a","a","b","b","a","a"], ["aa","bb","aa"], ["a","a","bbaa"], ["aabbaa"], etc.
   ```

6. **Empty string**

   * If `s == ""` you can return `[]` or `[[]]` depending on spec. The code above returns `[]` because we bail early; adjust if you prefer `[[]]` for empty input.


### Optimizations & variations ⚙️

1. **Precompute `isPal`** — best balance of simplicity and speed.
2. **Manacher’s algorithm?** — Manacher finds palindromic substrings in linear time overall, but integrating it into partition enumeration is complex and rarely necessary.
3. **Memoized DFS (cache by index)** — If you want to avoid recomputing partitions for the same suffix repeatedly, you can memoize the vector-of-vector results per starting index. Careful: caching and merging vectors can be expensive and may increase code complexity.
4. **Generate substrings lazily** — avoid `substr` copies by storing pairs `(start,len)` in `ds` and materialize strings only when adding to results. This reduces intermediate copies but complicates result construction.
5. **Iterative / BFS approach** — you can BFS on index positions and build partitions level-by-level; still backtracking-like and needs palindrome checks.


### Implementation tips & micro-optimizations ✅

* Use `const string& s` in recursive calls to avoid copying the string.
* Precompute `isPal` once — huge speedup.
* Reserve `ds` capacity: `ds.reserve(n)` to avoid repeated allocations.
* If memory is a concern and `n` is small, you may skip `isPal` and simple `isPal` checks; but DP is recommended.
* If you want lexicographically ordered partitions, ensure consistent loops and that substrings comparisons align. Usually not required.


### Frequently Asked Questions (FAQ) ❓

**Q: Do we have to return partitions in any specific order?**
> A: Usually not. Any order is accepted. If you need a specific order, you can sort the resulting vector-of-vectors.

**Q: Why precompute a palindrome table?**
> A: Without precomputation we would test `isPal` by scanning `O(length)` per substring and repeat many checks — resulting complexity balloons. Precompute to reduce each check to `O(1)`.

**Q: How big can the number of partitions be?**
> A: Exponential in `n` in the worst case (e.g., `s = "aaaaa..."`), because many partition combinations exist. Generating all of them is inherently exponential.

**Q: Can we find only the *minimum number* of cuts to partition into palindromes?**
> A: That's a different problem (`Palindromic Partitioning II`). It can be solved with DP to find the minimum cuts in `O(n^2)` time.

**Q: What if we need to avoid copying substrings frequently?**
> A: Store ranges `(start,end)` during recursion and only create `substr` when adding to final `res`. This reduces intermediate string allocations.
