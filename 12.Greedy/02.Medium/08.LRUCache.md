# ğŸ§  LRU Cache â€” O(1) Get & Put 
> (HashMap + Doubly Linked List)



## ğŸ“Œ Problem Statement

Design a data structure that supports an **LRU (Least Recently Used) Cache** with the following operations:

| Operation         | Description                                   |
| -- | --- |
| `get(key)`        | Return value of the key if present, else `-1` |
| `put(key, value)` | Insert or update the key-value pair           |

ğŸ“Œ **Constraints:**

* Cache has a fixed **capacity**
* When capacity is exceeded, remove the **least recently used** item
* Both `get` and `put` must work in **O(1)** time



## ğŸ§  Intuition

LRU means:

> If the cache is full, remove the item that **hasnâ€™t been used for the longest time**.

We need to support:

* Fast lookup â†’ **HashMap**
* Fast removal & insertion â†’ **Doubly Linked List**

So the winning combo is:

> **HashMap + Doubly Linked List**



## ğŸªœ Why Brute Force Fails

If we used:

* Only a list â†’ `O(n)` search
* Only a map â†’ no ordering information

We need **both speed and order**.



## ğŸš€ Optimal Design (Industry Standard)

### Data Structures Used

1. **Doubly Linked List**

   * Maintains usage order
   * Most Recently Used (MRU) â†’ near `head`
   * Least Recently Used (LRU) â†’ near `tail`

2. **Unordered Map**

   * `key â†’ Node*`
   * Gives O(1) access to nodes



## ğŸ§± High-Level Architecture

```
HEAD <-> [Most Recent] <-> ... <-> [Least Recent] <-> TAIL
```

* `head` and `tail` are **dummy nodes**
* Real data lives between them



## ğŸ§© Code Walkthrough

### ğŸ”¹ Node Structure

```cpp
class Node {
public:
    int key;
    int val;
    Node* next;
    Node* prev;
};
```

Each node stores:

* `key` â†’ needed to remove from map
* `value`
* `prev` and `next` pointers



### ğŸ”¹ Core Members

```cpp
Node* head = new Node(-1, -1);
Node* tail = new Node(-1, -1);

int cap;
unordered_map<int, Node*> m;
```

* `head` & `tail` â†’ dummy boundary nodes
* `cap` â†’ cache capacity
* `m` â†’ hashmap for O(1) access



### ğŸ”¹ Constructor

```cpp
LRUCache(int capacity) {
    cap = capacity;
    head->next = tail;
    tail->prev = head;
}
```

Initial empty list:

```
head <-> tail
```



## ğŸ”§ Helper Functions

### â• Add Node (Most Recently Used)

```cpp
void addNode(Node* newNode) {
    Node* temp = head->next;
    newNode->next = temp;
    newNode->prev = head;
    head->next = newNode;
    temp->prev = newNode;
}
```

Adds node **right after head** (MRU position).



### âŒ Delete Node

```cpp
void deleteNode(Node* delNode) {
    Node* delPrev = delNode->prev;
    Node* delNext = delNode->next;
    delPrev->next = delNext;
    delNext->prev = delPrev;
}
```

Removes a node from anywhere in O(1).



## ğŸ” `get(key)` Operation

```cpp
int get(int key_) {
    if (m.find(key_) != m.end()) {
        Node* resNode = m[key_];
        int res = resNode->val;
        m.erase(key_);
        deleteNode(resNode);
        addNode(resNode);
        m[key_] = head->next;
        return res;
    }
    return -1;
}
```

### What happens?

If key exists:

1. Fetch node from map
2. Remove it from current position
3. Move it to **front (MRU)**
4. Update map
5. Return value

If not:

* Return `-1`



## âœï¸ `put(key, value)` Operation

```cpp
void put(int key_, int value) {
    if (m.find(key_) != m.end()) {
        Node* existingNode = m[key_];
        m.erase(key_);
        deleteNode(existingNode);
    }
    if (m.size() == cap) {
        m.erase(tail->prev->key);
        deleteNode(tail->prev);
    }
    addNode(new Node(key_, value));
    m[key_] = head->next;
}
```

### Logic Breakdown

1. **Key already exists**

   * Remove old node
2. **Cache full**

   * Remove LRU node (`tail->prev`)
3. **Insert new node**

   * Add to front
   * Update map



## ğŸ§ª Dry Run Example

### Capacity = 2

```cpp
put(1,1) â†’ [1]
put(2,2) â†’ [2,1]
get(1)   â†’ [1,2]
put(3,3) â†’ evict 2 â†’ [3,1]
get(2)   â†’ -1
put(4,4) â†’ evict 1 â†’ [4,3]
```

Final outputs:

```
1
-1
-1
3
4
```

âœ” Correct behavior



## â±ï¸ Time & Space Complexity

| Operation | Complexity      |
| --- | --- |
| `get()`   | **O(1)**        |
| `put()`   | **O(1)**        |
| Space     | **O(capacity)** |



## ğŸ§  Why This Works

* HashMap â†’ instant access
* Doubly linked list â†’ instant reorder & deletion
* Dummy head/tail â†’ no edge-case headaches

This is **exactly how LRU caches are implemented in real systems**.



## âš ï¸ Important Improvements (Production-Level)

### 1ï¸âƒ£ Memory Leak Fix

You should delete evicted nodes:

```cpp
Node* lru = tail->prev;
m.erase(lru->key);
deleteNode(lru);
delete lru;
```



### 2ï¸âƒ£ Avoid Erasing & Re-inserting Map Entry

Instead of:

```cpp
m.erase(key);
m[key] = head->next;
```

You can just update pointer.



### 3ï¸âƒ£ Use `list` + `unordered_map` (STL Version)

Cleaner alternative:

```cpp
list<pair<int,int>> dll;
unordered_map<int, list<pair<int,int>>::iterator> mp;
```

But interviews **love** our pointer-based version.



## ğŸ™‹ FAQs

### â“ Why doubly linked list, not singly?

Because we need **O(1) deletion from middle**.



### â“ Why dummy head & tail?

Avoids null checks and edge cases.



### â“ Is this asked in interviews?

Yes â€” Google, Amazon, Microsoft, Meta, Netflix.



### â“ Is this system-design relevant?

Absolutely. LRU is used in:

* CPU caches
* Browser caches
* Databases
* OS page replacement
