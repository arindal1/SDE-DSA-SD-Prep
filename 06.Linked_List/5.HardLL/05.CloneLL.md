# Copy List with Random Pointer ðŸ§ ðŸ”

### Problem statement ðŸ“

You are given the head of a linked list where each node has:

```cpp
class Node {
public:
    int val;
    Node* next;
    Node* random;
};
```

Return a **deep copy** of the list: a new list of brand-new nodes where each node's `val`, `next`, and `random` match the original structure, but the new nodes are distinct objects (no shared nodes with the original).

Important: *random* pointers may be `nullptr`, may point to the same node as `next`, and may create complex cross-links (but the list is acyclic in `next` direction in standard constraints).

---

# Intuition âœ¨

We need to create new nodes and set two pointers for each:

* `next`: easy â€” copy structure.
* `random`: trickier because `random` may point to an arbitrary node that may not yet be created if we create copies left-to-right.

Three common approaches:

1. **Interleaving (O(n), O(1) extra)** â€” *best* for interviews:

   * Insert each new copy immediately after its original node: `orig -> copy -> origNext`.
   * `copy->random = orig->random->next` (because `orig->random->next` is the copy of `orig->random`).
   * Separate the two lists (restore original `next` pointers and extract copy).

2. **Hash map (O(n) time, O(n) extra)**:

   * Map original node -> copied node using `unordered_map`.
   * Two passes: create copies, then set `next` & `random` by lookup.

3. **Recursive + map** â€” similar to (2) but recursive; beware stack depth.

The interleaving approach avoids extra map memory by exploiting the fact we can insert copies inline.

---

# Walkthrough of the interleaving method (step-by-step) ðŸ”

Given: `A -> B -> C -> nullptr`, with various `random` links.

1. **Step 1 â€” Insert copied nodes**
   Convert to: `A -> A' -> B -> B' -> C -> C' -> nullptr`.
   Each `X'` is a new node with `val = X->val`.

2. **Step 2 â€” Set copied random pointers**
   For original `X`, if `X->random = Y` then set `X'->random = Y->next` (because `Y->next` is `Y'`).

3. **Step 3 â€” Separate the lists**
   Restore original `next` pointers and extract the copied list:

   * `X->next = X'->next` (which is next original node)
   * `X'->next = X'->next ? X'->next->next : nullptr` (next copy)

At the end you have the original list restored and a new deep-copy list.

---

# Full improved & annotated code (clean & safe) ðŸ§¾

```cpp
/*
// Definition for a Node.
class Node {
public:
    int val;
    Node* next;
    Node* random;
    
    Node(int _val) {
        val = _val;
        next = NULL;
        random = NULL;
    }
};
*/

class Solution {
public:
    Node* copyRandomList(Node* head) {
        if (!head) return nullptr;

        // 1) Interleave copied nodes with original nodes
        insertCopyInBetween(head);

        // 2) Set random pointers for copied nodes
        connectRandomPointers(head);

        // 3) Separate copied list from the original and restore original list
        return extractCopiedList(head);
    }

private:
    // Insert copy node after every original node: A->A'->B->B'->...
    void insertCopyInBetween(Node* head) {
        Node* cur = head;
        while (cur) {
            Node* next = cur->next;
            Node* copy = new Node(cur->val);
            cur->next = copy;
            copy->next = next;
            cur = next;
        }
    }

    // Set copy->random = original->random->next (if original->random exists)
    void connectRandomPointers(Node* head) {
        Node* cur = head;
        while (cur) {
            Node* copy = cur->next;
            if (cur->random) copy->random = cur->random->next;
            else copy->random = nullptr;
            // advance by two (skip the copy)
            cur = copy->next;
        }
    }

    // Extract copy list and restore original list structure.
    Node* extractCopiedList(Node* head) {
        Node* cur = head;

        // Use stack-allocated dummy to avoid extra heap allocation/leak
        Node dummy(0);
        Node* copyTail = &dummy;

        while (cur) {
            Node* copy = cur->next;
            Node* nextOriginal = copy->next; // may be nullptr

            // append copy to result
            copyTail->next = copy;
            copyTail = copyTail->next;

            // restore original 'next'
            cur->next = nextOriginal;

            // move forward
            cur = nextOriginal;
        }

        // terminate copied list
        copyTail->next = nullptr;
        return dummy.next;
    }
};
```

---

# Complexity analysis ðŸ“Š

* **Time complexity:** **O(n)** where `n` is the number of nodes. Each node is visited a constant number of times across the three passes (insert, connect randoms, extract).
* **Space complexity:** **O(1)** extra space (excluding the output list). We allocate new nodes for the copy (thatâ€™s required), but no extra data structures like maps.

---

# Test cases & edge cases ðŸ§ª

1. **Empty list**

   * Input: `head = nullptr` â†’ Output: `nullptr`.

2. **Single node, random = nullptr**

   * `1(nullptr)` â†’ copy `1(nullptr)`.

3. **Single node, random -> itself**

   * `1(random -> 1)` â†’ copied node's `random` should point to itself.

4. **Multiple nodes with randoms forward/backward**

   * `A -> B -> C`, `A.random = C`, `B.random = A`, `C.random = B` â€” ensures diverse cross-links.

5. **random pointers all null**

   * Works like ordinary `next` copy.

6. **random pointers to same node**

   * Multiple nodes pointing their random to a single node â€” copy points to single corresponding new node.

7. **Large list**

   * Performance O(n), memory O(n) for new nodes.

8. **Random cycles (via random only)**

   * `random` pointers can form cycles and that's okay â€” the algorithm handles them because the mapping from original node to copied node is implicit via next pointers.

---

# Tips, tricks & gotchas âœ¨

* **Always interleave copies before setting randoms.** Thatâ€™s the key trick: it gives direct access `orig->random->next` to the copy of the random target.
* **Advance pointers carefully.** In `connectRandomPointers` you must advance by two nodes (`cur = cur->next->next`) because the list is interleaved.
* **Restore original list** â€” many buggy solutions forget to restore original `next` pointers; doing so is important if the original list must remain unchanged.
* **Memory ownership:** The new nodes are allocated with `new`. If your environment requires manual cleanup later, ensure to delete them. For typical problems you return the head and the caller frees.
* **If allowed extra space and simpler code desired**, use an `unordered_map<Node*, Node*>` to map originals to copies: simpler but uses O(n) extra memory.

---

# Variations & extensions ðŸ”

1. **Use a Hash Map** (`orig -> copy`)

   * Two passes: create copy nodes and map them; second pass set `next` and `random` by lookup. Simpler but uses `O(n)` space.

2. **Recursive deep copy** (with map)

   * Useful if you prefer recursion, but watch recursion depth.

3. **Copy other graph-like structures**

   * The interleaving trick is specific to singly-linked lists with a `next`. For general graphs with arbitrary edges, use a `map` + DFS/BFS copy approach.

4. **Memory pooling / smart pointers**

   * For production, consider smart pointers or object pools to manage node lifetime safely.

---

# Frequently Asked Questions (FAQs) â“

**Q: Why does `copy->random = orig->random->next` work?**
A: After interleaving, every original `Y` has its copy `Y'` right after it (`Y->next == Y'`). So if `orig->random == Y`, then `orig->random->next` is `Y'`. That gives direct access to the copy without extra map.

**Q: Is the original list restored after the algorithm?**
A: Yes â€” the extraction phase restores `orig->next` to skip their copies and link to the next original. The final state leaves the original list structure unchanged.

**Q: What if `random` points to `nullptr`?**
A: The code checks for `cur->random` and sets `copy->random = nullptr` when needed.

**Q: Is this safe if the original list nodes have extra data or complex destructors?**
A: The algorithm only manipulates pointers and creates new nodes with `new`. Be careful if nodes manage external resources â€” consider copy constructors or RAII wrappers.

**Q: Which approach should I use in interviews?**
A: The interleaving technique is the expected optimal answer (O(n) time, O(1) extra). Briefly mention the hash map approach as an alternative and explain the tradeoff.

